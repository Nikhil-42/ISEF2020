import utils
import numba
import datetime
import itertools
import numpy as np
from numba import njit, prange
from numba.typed import List
from homebrew.network import JIT_Network, clone

# Called whenever a new population is spawned
@njit
def spawn_population(population_size, input_shape, output_shape, node_count):

    # Creates a list in which to store members of the population
    population = List()
    # Loops {population size} number of times
    for j in range(population_size):
        # Creates a new network with the specified input and output shapes and learning rate scaled based on node count
        new_net = JIT_Network(input_shape, output_shape, node_count, np.random.random()/node_count, j)
        node_count = new_net.node_count
        # Set the node count to display the actual node count because the network might make modifications to it
        # For each output node
        for node in range(1, output_shape+1):
            to_node = node_count-node
            # Create connections util it is connected to an input node
            while input_shape <= to_node:
                # Find a random node infront of the current receiving node
                from_node = to_node - np.random.randint(low=node_count/10, high=node_count/2+1)
                # If it's out of bounds set it to a random input node
                if from_node < 0:
                    from_node = np.random.randint(low=0, high=input_shape)
                # Add the connection
                new_net.add_connection(to_node, from_node)
                # Link the chain
                to_node = from_node
        # Randomly add more connnections on top of the constructed web
        connections = np.random.randint(0, high=node_count, size=(2, (node_count**2)/2)).astype(numba.int32)
        new_net.add_connections(connections[0], connections[1])
        # Place this network in the population
        population.append(new_net)
    return population

# Called whenever a network needs to be evaluated or reevaluated
@njit
def evaluation(x, y, val_x, val_y, compare, population):

    # Allocate an array for storing respective fitnesses
    fitnesses = np.empty(shape=len(population), dtype=numba.float64)
    # For each network in the population get a reference to the network and its index
    for j, network in enumerate(population):
        # Train the network
        traits = network.train(x, y, 1, 1000, 0.001)
        # Calculate and save its fitness
        if np.isnan(traits) or len(network.connections) == 0:
            fitnesses[j] = -1
        else:
            val = network.validate(val_x, val_y, compare)
            fitnesses[j] = val/(traits) # (val**int(network.node_count/2+10))/len(network.connections)
    # Return the respective fitnesses
    return fitnesses

# Called every generation to select parents
@njit
def selection(num_pairs, fitnesses, population):
    population_size = len(population)

    # Create a list of network indices where higher fitnesses are at the tail end of the list
    rank_list = fitnesses.argsort()

    # Because Numba doesn't support irregluar distributions and selection without replacement
    # I had to implement it myself

    choices = np.empty(0, dtype=np.int32)
    # For each index in the rank list
    for n, index in enumerate(rank_list):
        # Populate the choice list with n (the index of index) instances of index
        choices = np.append(choices, np.full(n+1, index, dtype=np.int32))

    # Allocate an array to store the pairs of parents
    pairs = np.empty((num_pairs, 2), dtype=np.int32)

    # For each pair
    for p in range(num_pairs):
        # Randomly choose one parent
        pairs[p, 0] = np.random.choice(choices) # This parent will tend to have higher fitness
        # Remove instances of the first parent and andomly choose the second parent
        pairs[p, 1] = np.random.choice(choices[np.invert(choices==pairs[p, 0]), ...])

    return pairs

@njit
def recombination(input_shape, output_shape, pairs, population):
    new_networks = List()

    for i in range(len(pairs)): # Using each of the pairs generated by the rank selection
        mom = population[pairs[i, 0]] # Set one parent as the mom
        dad = population[pairs[i, 1]] # And one as the dad

        # Merge their connections
        connections = mom.connections | dad.connections 
        if len(connections) > 0: # Redundant Safety check
            for j in range(np.random.randint(0, len(connections))):
                connections.pop() # And discard a random number of them

        # Create a new network with the same shape as the parents
        # and set the child's learning rate to be the average of the parents
        new_net = JIT_Network(input_shape, output_shape, mom.node_count, 0.5*(mom.learning_rate+dad.learning_rate), mom.id+dad.id)

        # Set the connections calculated above
        new_net.set_connections(connections)
        # Transfer the weights to the child (Lamarkian evolution)
        for connection in connections:
            if connection in mom.connections:
                new_net.set_weight(connection, mom.get_weight(connection)) # Make sure the weights are carried with each connections
            else:
                new_net.set_weight(connection, dad.get_weight(connection))

        # Add the child to the list of new networks
        new_networks.append(new_net)

    return new_networks

@njit
def mutation(population, mutations):
    mutated = List()

    # {~mutations} number of mutations should occur per generation
    for rand in np.random.random(mutations):
        # Randomly choose a network to mutate
        mutated.append(np.random.randint(low=0, high=len(population)))
        network = population[mutated[-1]]
        # 30% of the time it will undergo change to its connections
        if rand < 0.30:
            network.add_connection(np.random.randint(network.input_shape, network.node_count), np.random.randint(0, network.node_count-network.output_shape))
        # Sometime the learning rate will also change
        if rand < np.random.random():
            network.learning_rate += (rand-0.5)/network.node_count
        
    # Return a list of which networks were mutated 
    return mutated

# Simulation of competition between individuals in a species
@njit
def competition(fitnesses, population, new_fitnesses, new_networks):
    # Replace least fit network with more fit new_network
    for i, new_net in enumerate(new_networks):
        rank_list = fitnesses.argsort()
        if new_fitnesses[i] > fitnesses[rank_list[0]]:
            fitnesses[rank_list[0]] = new_fitnesses[i]
            population[rank_list[0]] = new_net

# Combine the aforementioned sets
@njit(parallel=True)
def evolution(x, y, val_x, val_y, compare, population_size, node_count, generations):
    # First spawn the initial population 
    population = spawn_population(population_size, x.shape[1], y.shape[1], node_count)
    # Then evalutate them
    fitnesses = evaluation(x, y, val_x, y, compare, population)
    # and save the best one
    best_fitness = fitnesses.max()
    best_network = clone(population[fitnesses.argsort()[-1]])    
    print(fitnesses.max(), best_fitness)
    # Repeat this {generations} number of times
    for i in range(generations):
        # Apply mutations and reevaluate mutated networks
        mutated = mutation(population, int(population_size*0.075))
        mutation_fitnesses = evaluation(x, y, val_x, val_y, compare, [population[mutate] for mutate in mutated])
        for j in prange(len(mutated)):
            fitnesses[mutated[j]] = mutation_fitnesses[j]

        # Pair up parents for offspring
        pairs = selection(int(population_size*0.15), fitnesses, population)
        # Breed the parent pairs and evaluate offspring
        new_networks = recombination(x.shape[1], y.shape[1], pairs, population)
        new_fitnesses = evaluation(x, y, val_x, val_y, compare, new_networks)
        # Remove networks with the least fitness
        competition(fitnesses, population, new_fitnesses, new_networks)

        # Save the best network
        print("Generation #", i, " Max Fitness:", best_fitness)
        if fitnesses.max() > best_fitness:
            print("New Best Fitness")
            best_fitness = fitnesses.max()
            best_network = clone(population[fitnesses.argsort()[-1]])

    # Return the saved best network and validate it
    accuracy = best_network.validate(val_x, val_y, compare)
    print("Accuracy: ", accuracy*100,"%")
    return best_network, best_fitness, accuracy

# Search funcation for optimizing node count as well+
@njit
def evolve_node_count(x, y, val_x, val_y, compare, population_count, population_size, node_cap, generations, target_accuracy, r):
    # Initialize the psuedorandom number generator to allow for reprodceibility
    np.random.seed(r)
    # Allocate space to save the best network
    best_fitness = 0
    best_accuracy = 0
    best_network = None
    # Set the node floor to be equal to the number inputs + number of outputs
    node_floor = x.shape[1]+y.shape[1]+1
    # Repeat {population count} number of times
    for i in range(population_count):
        # Select a random node count between the floor and cap
        node_count = np.random.randint(node_floor, node_cap)
        print("Population:" ,i, " Node Count:", node_count)
        # Run the evolutionary search which returns a network, fitness, and accuracy
        network, fitness, accuracy = evolution(x, y, val_x, val_y, compare, population_size, node_count, generations)
        # If it meets minimum requirements
        if accuracy >= target_accuracy:
            # Check if it is the very best
            if fitness > best_fitness:
                # and save it
                print("Replaced ", best_fitness, " with ", fitness)
                node_cap = min(node_cap, node_count)
                best_fitness = fitness
                best_network = network
                best_accuracy = accuracy
            # Also check whether the range must be expanded
            if node_count == node_floor:
                node_floor -= int(node_count/4)
        else:
            # If it does meet minimum requirements but its better than before
            if not best_accuracy > target_accuracy and accuracy > best_accuracy:
                # Save it
                print("Replaced ", best_fitness, " with ", fitness)
                best_fitness = fitness
                best_network = network
                best_accuracy = accuracy
            # Adjust the range
            node_floor += int(0.5 * (node_count-node_floor)) + 1
        
        # If the range converges early break the loop
        print(node_floor, "<= node_count <", node_cap)
        if node_cap==node_floor:
            break

    # Return the result
    print("Node Count:", best_network.node_count)
    print(best_network.input_shape)
    print(best_network.output_shape)
    print("Weighted Connections:")
    for c in best_network.connections:
        print(c,':', best_network.weights[c])
    print("Biases:", list(best_network.nodes[:,2]))
    print("Best Accuracy:", best_network.validate(val_x, val_y, compare)*100,'%')
    return best_network

if __name__ == "__main__":
    np.random.seed(0)

    x = np.array([[1, 0] if rand < 0.25 else [0, 1] if rand < 0.5 else [1, 1] if rand < 0.75 else [0,0] for rand in np.random.random(60000)], dtype=int)
    y = np.array([[1,] if np.sum(itm)==1 else [0,] for itm in x], dtype=int)

    with utils.OutSplit('xor_evolution_test'):
        # network, fitness, accuracy = evolution(x, y, x, y, utils.jit_round_compare, 30, 4, 50)
        # print(fitness, accuracy, network.validate(x, y, utils.jit_round_compare))
        best_xor = evolve_node_count(x, y, x, y, utils.jit_round_compare, population_count=30, population_size=15, node_cap=50, generations=100, target_accuracy=1, r=2)
        best_xor.predict(np.array([[0, 1], [1, 1], [0, 0], [1, 0]]))
        utils.display_network(best_xor, 'xor')